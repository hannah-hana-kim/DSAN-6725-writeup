[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Our Vision",
    "section": "",
    "text": "casual.ai\n\n\nCASUAL.AI is a smart outfit recommendation AI agent. The idea behind CASUAL.AI is to make daily outfit decisions faster and smarter. We wanted to solve an everyday problem: “What should I wear today?” - and more importantly, “What goes well together?”\nPeople often spend 15–20 minutes each day choosing an outfit, only to second-guess if it fits the occasion or the weather. CASUAL.AI reduces this decision fatigue by acting like a digital personal stylist.\nIt analyzes your wardrobe, the event type, and real-time weather to offer curated outfit suggestions. Over time, it learns from your choices and preferences to make even smarter recommendations.\nThe goal is to help users make better outfit choices by providing personalized recommendations based on their wardrobe, occasions, and the current weather conditions.\nCASUAL.AI works like a personalized stylist that helps users match clothes based on occasion and weather; just like a digital stylist that understands your wardrobe."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Our Vision",
    "section": "",
    "text": "casual.ai\n\n\nCASUAL.AI is a smart outfit recommendation AI agent. The idea behind CASUAL.AI is to make daily outfit decisions faster and smarter. We wanted to solve an everyday problem: “What should I wear today?” - and more importantly, “What goes well together?”\nPeople often spend 15–20 minutes each day choosing an outfit, only to second-guess if it fits the occasion or the weather. CASUAL.AI reduces this decision fatigue by acting like a digital personal stylist.\nIt analyzes your wardrobe, the event type, and real-time weather to offer curated outfit suggestions. Over time, it learns from your choices and preferences to make even smarter recommendations.\nThe goal is to help users make better outfit choices by providing personalized recommendations based on their wardrobe, occasions, and the current weather conditions.\nCASUAL.AI works like a personalized stylist that helps users match clothes based on occasion and weather; just like a digital stylist that understands your wardrobe."
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "Conclusion"
  },
  {
    "objectID": "data_prep.html",
    "href": "data_prep.html",
    "title": "Data Preprocessing",
    "section": "",
    "text": "The file names of the images in the dataset are changed to a more readable format. The original file names are in the format 01.jpg, 02.jpg, etc. The new file names are in the format 01_pants.jpg, 02_pants.jpg, etc.\n\n\nCode\n%%bash\n# Rename shorts\ncd clothes/train/shorts\nfor i in {1..40}; do mv \"$(printf \"%02d\" $i).jpg\" \"$(printf \"%02d\" $i)_shorts.jpg\"; done\n\n# Rename pants\ncd ../pants\nfor i in {1..40}; do mv \"$(printf \"%02d\" $i).jpg\" \"$(printf \"%02d\" $i)_pants.jpg\"; done\n\n# Rename shirts\ncd ../shirts\nfor i in {1..40}; do mv \"$(printf \"%02d\" $i).jpg\" \"$(printf \"%02d\" $i)_shirts.jpg\"; done\n\n# Rename t-shirts\ncd ../t-shirts\nfor i in {1..40}; do mv \"$(printf \"%02d\" $i).jpg\" \"$(printf \"%02d\" $i)_t-shirts.jpg\"; done\ndone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe trained our agent using Kaggle’s clothing dataset, categorized into pants, shorts, shirts, and t-shirts.\n\n\n\n\n\n\nmetadata\n\n\nMetadata includes the following: - File name - Categories: The type of clothing (e.g., pants, shorts, shirts, t-shirts) - Color: The color of the clothing item - Style: The occasion for the clothing item (e.g., casual, formal, sporty) - Gender: The gender for the clothes (e.g., male, female, unisex) - Sleeve length: The length of the sleeves (e.g., short, long, sleeveless)\n\n\nCode\nimport os\nfrom pillow_heif import register_heif_opener\nfrom PIL import Image\n\n# Register HEIC opener\nregister_heif_opener()\n\n# Specify the file path of the HEIC image\nheic_file = \"images/pants_01.heic\"  # Replace with the actual file path\njpg_file = heic_file.rsplit('.', 1)[0] + '.jpg'\n\n# Open and convert the image\ntry:\n    img = Image.open(heic_file)\n    img.save(jpg_file, \"JPEG\")\n    print(f\"Converted: {os.path.basename(heic_file)} -&gt; {os.path.basename(jpg_file)}\")\nexcept Exception as e:\n    print(f\"Failed to convert {os.path.basename(heic_file)}: {e}\")\n\n\nConverted: pants_01.heic -&gt; pants_01.jpg\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe used HuggingFace’s segment-anything library to segment the clothing items in the images. The segmentation masks are saved in a separate folder for each image. The masks are used to create a binary mask for each clothing item, which is then used to train the agent.\n\n\nCode\nfrom PIL import Image\nimport os\n\n_GPU_INDEX = 0\n\nexample_input_path = \"./clothes/test/pants/01_pants.jpg\"\nexample_dir = \".clothes/test/pants\"\n\nos.makedirs(example_dir, exist_ok=True)\ninput_raw = Image.open(example_input_path)\n\n# show the input image\ninput_raw_copy = input_raw.copy()\ninput_raw_copy.thumbnail((256, 256))\ninput_raw_copy\n\n# initialize the Segment Anything model\npredictor = sam_init(_GPU_INDEX)\n\n# preprocess the input image\ninput_256 = preprocess(predictor, input_raw)\ninput_256\n\nimport os\nimport torch\n\n# GPU Index (Set to 0 if using CUDA, otherwise it'll default to CPU)\n_GPU_INDEX = 0\n\n# Root directory for dataset\nroot_dir = \"./clothes/test\"\ncategories = [\"pants\", \"shirts\", \"shorts\", \"t-shirts\"]\n\n# Initialize the Segment Anything Model (SAM)\npredictor = sam_init(_GPU_INDEX)\n\ndef preprocess(predictor, raw_im, lower_contrast=False):\n    \"\"\"Preprocess image using SAM.\"\"\"\n    raw_im.thumbnail([512, 512], Image.Resampling.LANCZOS)\n    image_sam = sam_out_nosave(predictor, raw_im.convert(\"RGB\"), pred_bbox(raw_im))\n    input_256 = image_preprocess_nosave(image_sam, lower_contrast=lower_contrast, rescale=True)\n    torch.cuda.empty_cache()\n    return input_256\n\n# Iterate through each category (pants, shirt, shorts, t-shirt)\nfor category in categories:\n    input_folder = os.path.join(root_dir, category)\n    output_folder = os.path.join(root_dir, f\"{category}_segmented\")\n\n    # Create output folder if it doesn't exist\n    os.makedirs(output_folder, exist_ok=True)\n\n    # Process all images in the folder\n    for filename in os.listdir(input_folder):\n        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n            image_path = os.path.join(input_folder, filename)\n            output_path = os.path.join(output_folder, filename)\n\n            # Open and process the image\n            input_raw = Image.open(image_path)\n            processed_image = preprocess(predictor, input_raw)\n\n            # Save processed image\n            processed_image.save(output_path)\n            print(f\"Saved: {output_path}\")\n\nprint(\"All images processed and saved!\")"
  },
  {
    "objectID": "data_prep.html#data-preprocessing",
    "href": "data_prep.html#data-preprocessing",
    "title": "Data Preprocessing",
    "section": "",
    "text": "The file names of the images in the dataset are changed to a more readable format. The original file names are in the format 01.jpg, 02.jpg, etc. The new file names are in the format 01_pants.jpg, 02_pants.jpg, etc.\n\n\nCode\n%%bash\n# Rename shorts\ncd clothes/train/shorts\nfor i in {1..40}; do mv \"$(printf \"%02d\" $i).jpg\" \"$(printf \"%02d\" $i)_shorts.jpg\"; done\n\n# Rename pants\ncd ../pants\nfor i in {1..40}; do mv \"$(printf \"%02d\" $i).jpg\" \"$(printf \"%02d\" $i)_pants.jpg\"; done\n\n# Rename shirts\ncd ../shirts\nfor i in {1..40}; do mv \"$(printf \"%02d\" $i).jpg\" \"$(printf \"%02d\" $i)_shirts.jpg\"; done\n\n# Rename t-shirts\ncd ../t-shirts\nfor i in {1..40}; do mv \"$(printf \"%02d\" $i).jpg\" \"$(printf \"%02d\" $i)_t-shirts.jpg\"; done\ndone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe trained our agent using Kaggle’s clothing dataset, categorized into pants, shorts, shirts, and t-shirts.\n\n\n\n\n\n\nmetadata\n\n\nMetadata includes the following: - File name - Categories: The type of clothing (e.g., pants, shorts, shirts, t-shirts) - Color: The color of the clothing item - Style: The occasion for the clothing item (e.g., casual, formal, sporty) - Gender: The gender for the clothes (e.g., male, female, unisex) - Sleeve length: The length of the sleeves (e.g., short, long, sleeveless)\n\n\nCode\nimport os\nfrom pillow_heif import register_heif_opener\nfrom PIL import Image\n\n# Register HEIC opener\nregister_heif_opener()\n\n# Specify the file path of the HEIC image\nheic_file = \"images/pants_01.heic\"  # Replace with the actual file path\njpg_file = heic_file.rsplit('.', 1)[0] + '.jpg'\n\n# Open and convert the image\ntry:\n    img = Image.open(heic_file)\n    img.save(jpg_file, \"JPEG\")\n    print(f\"Converted: {os.path.basename(heic_file)} -&gt; {os.path.basename(jpg_file)}\")\nexcept Exception as e:\n    print(f\"Failed to convert {os.path.basename(heic_file)}: {e}\")\n\n\nConverted: pants_01.heic -&gt; pants_01.jpg\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe used HuggingFace’s segment-anything library to segment the clothing items in the images. The segmentation masks are saved in a separate folder for each image. The masks are used to create a binary mask for each clothing item, which is then used to train the agent.\n\n\nCode\nfrom PIL import Image\nimport os\n\n_GPU_INDEX = 0\n\nexample_input_path = \"./clothes/test/pants/01_pants.jpg\"\nexample_dir = \".clothes/test/pants\"\n\nos.makedirs(example_dir, exist_ok=True)\ninput_raw = Image.open(example_input_path)\n\n# show the input image\ninput_raw_copy = input_raw.copy()\ninput_raw_copy.thumbnail((256, 256))\ninput_raw_copy\n\n# initialize the Segment Anything model\npredictor = sam_init(_GPU_INDEX)\n\n# preprocess the input image\ninput_256 = preprocess(predictor, input_raw)\ninput_256\n\nimport os\nimport torch\n\n# GPU Index (Set to 0 if using CUDA, otherwise it'll default to CPU)\n_GPU_INDEX = 0\n\n# Root directory for dataset\nroot_dir = \"./clothes/test\"\ncategories = [\"pants\", \"shirts\", \"shorts\", \"t-shirts\"]\n\n# Initialize the Segment Anything Model (SAM)\npredictor = sam_init(_GPU_INDEX)\n\ndef preprocess(predictor, raw_im, lower_contrast=False):\n    \"\"\"Preprocess image using SAM.\"\"\"\n    raw_im.thumbnail([512, 512], Image.Resampling.LANCZOS)\n    image_sam = sam_out_nosave(predictor, raw_im.convert(\"RGB\"), pred_bbox(raw_im))\n    input_256 = image_preprocess_nosave(image_sam, lower_contrast=lower_contrast, rescale=True)\n    torch.cuda.empty_cache()\n    return input_256\n\n# Iterate through each category (pants, shirt, shorts, t-shirt)\nfor category in categories:\n    input_folder = os.path.join(root_dir, category)\n    output_folder = os.path.join(root_dir, f\"{category}_segmented\")\n\n    # Create output folder if it doesn't exist\n    os.makedirs(output_folder, exist_ok=True)\n\n    # Process all images in the folder\n    for filename in os.listdir(input_folder):\n        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n            image_path = os.path.join(input_folder, filename)\n            output_path = os.path.join(output_folder, filename)\n\n            # Open and process the image\n            input_raw = Image.open(image_path)\n            processed_image = preprocess(predictor, input_raw)\n\n            # Save processed image\n            processed_image.save(output_path)\n            print(f\"Saved: {output_path}\")\n\nprint(\"All images processed and saved!\")"
  },
  {
    "objectID": "data_prep.html#segmentation",
    "href": "data_prep.html#segmentation",
    "title": "Data Preprocessing",
    "section": "Segmentation",
    "text": "Segmentation\nWe applied image segmentation using HuggingFace’s SAM model to remove the background of the images in order to focus only on the clothing items."
  },
  {
    "objectID": "model_1.html",
    "href": "model_1.html",
    "title": "Model 1",
    "section": "",
    "text": "Once the images were segmented, we extracted features from each using a ResNet-18 model. Resnet is one of the well-known models for image classification, and it was perfect for our data since Resnet is the best model for feature extraction. We were able to achieve 99.3% of accuracy from this model.\nOnce we achieved high accuracy, not only did we use cloth embeddings but we also built a similarity index using Faiss and saved our feature extraction model for use in the later stages.\nWhen evaluating the model, we tested similarity queries for random and top 5 matches, and also analyzed intra- and inter-class distances to confirm whether the embeddings were valid or not. We also visualized the embedding space using t-SNE, which showed clear separation between the categories.\nThese embeddings were essential for the second model, which we’ll get into next.”"
  },
  {
    "objectID": "data_prep.html#data-preprocessing-1",
    "href": "data_prep.html#data-preprocessing-1",
    "title": "Data Preprocessing",
    "section": "",
    "text": "We changed the filenames for the sake of data integrity and consistency.\n\n\n\n \nWe trained our agent using Kaggle’s clothing dataset, categorized into pants, shorts, shirts, and t-shirts.\n\n\n\n\nWe also created metadata manually including color, gender, and sleeve length."
  }
]