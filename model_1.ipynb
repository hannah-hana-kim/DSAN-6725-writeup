{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Model 1\n",
    "format:\n",
    "  html:\n",
    "    embed-resources: true\n",
    "    code-fold: false\n",
    "execute:\n",
    "  echo: true\n",
    "  warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the images were segmented, we extracted features from each using a ResNet-18 model. Resnet is one of the well-known models for image classification, and it was perfect for our data since Resnet is the best model for feature extraction. We were able to achieve 99.3% of accuracy from this model. \n",
    "\n",
    "Once we achieved high accuracy, not only did we use cloth embeddings but we also built a similarity index using Faiss and saved our feature extraction model for use in the later stages.\n",
    "\n",
    "When evaluating the model, we tested similarity queries for random and top 5 matches, and also analyzed intra- and inter-class distances to confirm whether the embeddings were valid or not. We also visualized the embedding space using t-SNE, which showed clear separation between the categories.\n",
    "\n",
    "These embeddings were essential for the second model, which we’ll get into next.”\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
